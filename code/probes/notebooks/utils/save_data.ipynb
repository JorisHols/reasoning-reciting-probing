{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from datasets import load_from_disk\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model responses an accuracy\n",
    "import hashlib\n",
    "import re\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def get_label(expr, base):\n",
    "    lhs, rhs = expr.split(\"+\")\n",
    "    lhs_base10 = int(lhs, base)\n",
    "    rhs_base10 = int(rhs, base) \n",
    "    sum_base10 = lhs_base10 + rhs_base10\n",
    "    return np.base_repr(sum_base10, base)\n",
    "\n",
    "def unescape(str):\n",
    "    placeholder = \"<TMP>\"\n",
    "    assert placeholder not in str\n",
    "    return str.replace(\"\\\\\\\\n\", placeholder).replace(\"\\\\n\", \"\\n\").replace(placeholder, \"\\\\n\").replace(\"\\\\\\\\r\", placeholder).replace(\"\\\\r\", \"\\r\").replace(placeholder, \"\\\\r\")\n",
    "\n",
    "\n",
    "def parse_output(output):\n",
    "    if len(output) == 0:\n",
    "        return \"FAILED\"\n",
    "\n",
    "    output_hash = hashlib.md5(output.encode(\"utf-8\")).hexdigest()\n",
    "    if output_hash in {\"a7994fde4fba7d27500e6f03008abd7c\"}:\n",
    "        return \"FAILED\"\n",
    "\n",
    "    output = output.replace(\",\", \"\").replace(\"ะก\", \"C\")\n",
    "\n",
    "    if (match := re.search(\"^[0-9A-Z]+$\", output)) is not None:\n",
    "        return output\n",
    "\n",
    "    output = output.rstrip(\"\\n$ `\")\n",
    "    if output.endswith(\"\\n\"):\n",
    "        output = output[:-1]\n",
    "    output = output.replace(\"\\\\text{\", \"\")\n",
    "\n",
    "    boxed_regex = r\"boxed{(\\\\text{)?(result=)?([0-9A-Z]+(_{?[0-9]+}?)?\\s*\\+\\s*[0-9A-Z]+(_{?[0-9]+}?)?\\s*=\\s*)?(0x)?([0-9A-Za-f \\\\.]+)(_ ?{?(base-)?([0-9]+|ten)}?)?}?(_{?([0-9]+|ten)}?)?}\"\n",
    "    get_result_from_boxed_regex = lambda match: match[-6].replace(\" \", \"\").replace(\"\\\\\", \"\")\n",
    "    # match all \\boxed{...} but also make sure there's only one match\n",
    "    match = re.findall(boxed_regex, output)\n",
    "    if len(match) >= 1 and all(get_result_from_boxed_regex(m) == get_result_from_boxed_regex(match[0]) for m in match):\n",
    "        return get_result_from_boxed_regex(match[0])\n",
    "\n",
    "    last_line = output.split(\"\\n\")[-1]\n",
    "    match = re.findall(boxed_regex, last_line)\n",
    "    if len(match) >= 1 and all(get_result_from_boxed_regex(m) == get_result_from_boxed_regex(match[0]) for m in match):\n",
    "        return get_result_from_boxed_regex(match[0])\n",
    "\n",
    "    last_line = output.rstrip(\" .\").split(\".\")[-1]\n",
    "    match = re.findall(boxed_regex, last_line)\n",
    "    if len(match) >= 1 and all(get_result_from_boxed_regex(m) == get_result_from_boxed_regex(match[0]) for m in match):\n",
    "        return get_result_from_boxed_regex(match[0])\n",
    "\n",
    "    if (match := re.search(r\"\\\\boxed{[0-9A-Z]+}(_{?[0-9]+}?)?\\s*\\+\\s*\\\\boxed{[0-9A-Z]+}(_{?[0-9]+}?)?\\s*=\\s*\\\\boxed{([0-9A-Z]+)}(_{?[0-9]+}?)?\\.?$\", last_line)) is not None:\n",
    "        return match.groups()[-2]\n",
    "\n",
    "    if (match := re.search(r\"\\\\boxed{([0-9A-Z]+)_{?[0-9]+}?\\s*=\\s*[0-9A-Z]+_{?10}?}\\$?\\.?$\", last_line)) is not None:\n",
    "        return match.groups()[0]\n",
    "\n",
    "    if (match := re.search(r\"\\$?[0-9A-Z]+(_{?[0-9]+}?)\\s*\\+\\s*[0-9A-Z]+(_{?[0-9]+}?)\\s*=\\s*(0x)?([0-9A-Z]+)(_{?[0-9]+}?)\\$?( in base-[0-9]+)?\\.?$\", output)) is not None:\n",
    "        return match.groups()[-3]\n",
    "\n",
    "    if (match := re.search(r\"(=|is):?\\s*\\$?\\\\boxed{(0x)?([0-9A-Z]+)}\\$? \\(?in base-[0-9]+\\)?,?( and| or| =) \\$?\\\\boxed{(0x)?[0-9A-Z]+}\\$? \\(?in (base-10|decimal)\\)?\\.?$\", output)) is not None:\n",
    "        return match.groups()[2]\n",
    "    if (match := re.search(r\"(=|is):?\\s*\\$?\\\\boxed{(0x)?[0-9A-Z]+}\\$? \\(?in (base-10|decimal)\\)?,?( and| or| =) \\$?\\\\boxed{(0x)?([0-9A-Z]+)}\\$? \\(?in base-[0-9]+\\)?\\.?$\", output)) is not None:\n",
    "        return match.groups()[-1]\n",
    "    # \\boxed{207}_{10}$ which in base-11 is $\\boxed{18A}$.\n",
    "    if (match := re.search(r\"\\\\boxed{[0-9A-Z]+}_\\{10\\}\\$? which in base-[0-9]+ is \\$?\\\\boxed{(0x)?([0-9A-Z]+)}\\$?\\.?$\", output)) is not None:\n",
    "        return match.groups()[-1]\n",
    "    # 39 + 31 = 5A\\boxed{}\n",
    "    if (match := re.search(r\"[0-9]+\\s*\\+\\s*[0-9]+\\s*=\\s*([0-9A-Z]+)\\\\boxed\\{\\}\\.?$\", output)) is not None:\n",
    "        return match.groups()[-1]\n",
    "\n",
    "    # \\boxed{result}\\n62\n",
    "    if (match := re.search(r\"\\\\boxed{result}\\s*(\\n|=)?\\s*([0-9A-Z+*^. ]+=\\s*)?([0-9A-Z.]+)\\$?\\.?\\**}?$\", output)) is not None:\n",
    "        return match.groups()[-1]\n",
    "\n",
    "    # \\boxed{result: 62}\n",
    "    if (match := re.search(r\"\\\\boxed{result: ([0-9A-Z]+)}$\", output)) is not None:\n",
    "        return match.groups()[0]\n",
    "\n",
    "    match = re.findall(r\"[0-9A-Z]+\\s*\\+\\s*[0-9A-Z]+\\s*=\\s*(0x)?([0-9A-Z]+)\", last_line)\n",
    "    if len(match) == 1:\n",
    "        return match[0][1]\n",
    "\n",
    "    match_after_semicolon = r\"\\s+((\\n|[ 0-9A-Z*^])+(\\+(\\n|[ 0-9A-Z*^])+)+(=|-+|_+)\\s*)*([0-9A-Z]+)\\s*(\\(?(in )?base-[0-9]+\\)?)?(, which [^,.]+)?(\\s*\\([^()]+\\))?\\.?$\"\n",
    "    if (match := re.search(r\"\\n([0-9A-Z]+)$\", output)) is not None:\n",
    "        return match.groups()[-1]\n",
    "    if (match := re.search(r\" in base-[0-9]+ is (equal to )?\\\"?(0x)?([0-9A-Z]+)\\\"?( base-[0-9]+)?(, (or|since) [^.]+)?( \\([^()]+\\))?\\.$\", output)) is not None:\n",
    "        return match.groups()[-5]\n",
    "    if (match := re.search(r\" in base-[0-9]+: \\$?([0-9A-Z]+)\\$?\\.$\", output)) is not None:\n",
    "        return match.groups()[-1]\n",
    "    if (match := re.search(r\" the base-[0-9]+ sum: ([0-9A-Z]+)\\.$\", output)) is not None:\n",
    "        return match.groups()[-1]\n",
    "    if (match := re.search(r\"the result in base-[0-9]+ is ([0-9A-Z]+), which is equal to [0-9 *^+()]+\\.$\", output)) is not None:\n",
    "        return match[1]\n",
    "    if (match := re.search(r\"the sum of [0-9A-Z]+ and [0-9A-Z]+ (in base-[0-9]+ )?(is|as):?\" + match_after_semicolon, output)) is not None:\n",
    "        return match.groups()[-5]\n",
    "    if (match := re.search(r\"the result of [0-9A-Z]+\\s*\\+\\s*[0-9A-Z]+ (in base-[0-9]+ )?(is|as):?\" + match_after_semicolon, output)) is not None:\n",
    "        return match.groups()[-5]\n",
    "    if (match := re.search(r\"[0-9A-Z]+\\s*\\+\\s*[0-9A-Z]+( in base-[0-9]+)?,? (which )?(equals|is equal to|as):? \\$?([0-9A-Z]+)\\$?(, written as [0-9A-Z]+)?\\.?$\", output)) is not None:\n",
    "        return match.groups()[-2]\n",
    "    if (match := re.search(r\"in base-10 is \\$?[0-9]+\\$?,? (which )?(equals|is equal to|as):? \\$?([0-9A-Z]+)\\$?(, written as [0-9A-Z]+)?\\.?$\", output)) is not None:\n",
    "        return match.groups()[-2]\n",
    "    if (match := re.search(r\"[0-9A-Z]+\\s*\\+\\s*[0-9A-Z]+\\s*=\\s*([0-9A-Z]+)( in base-[0-9]+)?\\.?$\", output)) is not None:\n",
    "        return match.groups()[-2]\n",
    "    if (match := re.search(r\"we can simply write the result as ([0-9A-Z]+)\\.?$\", output)) is not None:\n",
    "        return match.groups()[-1]\n",
    "    if (match := re.search(r\"which can be written as ([0-9A-Z]+)\\.?$\", output)) is not None:\n",
    "        return match.groups()[-1]\n",
    "    if (match := re.search(r\"(which gives|giving) us the( base-[0-9]+)? number ([0-9A-Z]+)\\.?$\", output)) is not None:\n",
    "        return match.groups()[-1]\n",
    "    if (match := re.search(r\"the final result is simply the sum of the tens and ones places: ([0-9A-Z]+)\\.?$\", output)) is not None:\n",
    "        return match.groups()[-1]\n",
    "    if (match := re.search(r\"the result is simply the combination of these two sums: ([0-9A-Z]+)\\.?$\", output)) is not None:\n",
    "        return match.groups()[-1]\n",
    "    if (match := re.search(r\"we have ([0-9A-Z]+) in base-[0-9]+ as the (final answer for|result of|sum of) [0-9A-Z]+ (\\+|and) [0-9A-Z]+\\.$\", output)) is not None:\n",
    "        return match[1]\n",
    "    if (match := re.search(r\"we (have|get|end up with) ([0-9A-Z]+)( in base-[0-9]+)? as the( final)? (result|answer|sum)( in base-[0-9]+)?\\.$\", output)) is not None:\n",
    "        return match.groups()[1]\n",
    "    if (match := re.search(r\"(=| is) \\\"?([0-9A-Z]+)\\\"?\\s*(\\s+\\(?(in )?base-[0-9]+\\)?)?\\.?$\", output)) is not None:\n",
    "        return match.groups()[1]\n",
    "    if (match := re.search(r\"( final)?( base-[0-9]+)? (result|answer|sum)( in base-[0-9]+)?( is)?( simply)?( of)?( as)?:?\" + match_after_semicolon, output)) is not None:\n",
    "        return match.groups()[-5]\n",
    "    if (match := re.search(r\"we get:\" + match_after_semicolon, output)) is not None:\n",
    "        return match.groups()[-5]\n",
    "    if (match := re.search(r\"we can add the two numbers in base-[0-9]+:\" + match_after_semicolon, output)) is not None:\n",
    "        return match.groups()[-5]\n",
    "    if (match := re.search(r\"[tT]he combination of these sums:\\s+([0-9A-Z]+)(\\(in base-[0-9]+\\))?\\.?$\", output)) is not None:\n",
    "        return match.groups()[-2]\n",
    "    if (match := re.search(r\"(Result|Answer)( is)?:?\\s+([0-9A-Z]+)\\.?$\", output)) is not None:\n",
    "        return match.groups()[-1]\n",
    "    if (match := re.search(r\"The decimal equivalent of \\$?([0-9A-Z]+)\\$? is therefore \\$?[0-9A-Z]+\\$?\\.?$\", output)) is not None:\n",
    "        return match.groups()[0]\n",
    "    if (match := re.search(r\"(T|t)he final (result|answer) is:?\\s+([0-9A-Z ]+\\s*\\+\\s*[0-9A-Z ]+\\s*(=|-+)+\\s*)?([0-9A-Z ]+)(\\(in base-[0-9]+\\))?\\.?\\**$\", output)) is not None:\n",
    "        return match.groups()[-2].replace(\" \", \"\")\n",
    "    if (match := re.search(r\" in base-[0-9]+ is (equal to )?\\\"?(0x)?([0-9A-Z ]+)\\\"?(, or [^,.]+)?\\.$\", output)) is not None:\n",
    "        return match.groups()[-2].replace(\" \", \"\")\n",
    "    if (match := re.search(r\"( |(\\n))([0-9A-Z]+) \\(?in base-[0-9]+\\)?\\.$\", output)) is not None:\n",
    "        return match.groups()[-1]\n",
    "\n",
    "    #print(\"Failed to parse output:\", output)\n",
    "    #print(output_hash)\n",
    "    return \"FAILED\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "base = 10\n",
    "type = \"probe\"\n",
    "with_intervention = True\n",
    "alpha = 0.0\n",
    "layer = 9\n",
    "model_name = 'meta-llama/Llama-3.1-8B'\n",
    "\n",
    "\n",
    "if with_intervention:\n",
    "    input_dir = f\"../../../../results/arithmetic/{type}/base{base}/with_intervention/alpha_{alpha:0.2f}_layer_dofm_{layer}/combined\"\n",
    "    output_dir = f\"{model_name.split('/')[-1]}/base{base}/with_intervention/alpha_{alpha:0.2f}_layer_dofm_{layer}\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "else:\n",
    "    input_dir = f\"../../../../results/arithmetic/{type}/base{base}/base{base}\"\n",
    "    output_dir = f\"{model_name.split('/')[-1]}/base{base}\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    alpha = 0.0\n",
    "    layer = None\n",
    "\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "dataset = load_from_disk(input_dir)\n",
    "activations = dataset[\"residual_activations\"]\n",
    "# Save expressions and LLM responses to a file\n",
    "expressions = dataset[\"expr\"]\n",
    "llm_responses = dataset[\"llm_response\"]\n",
    "\n",
    "print(len(expressions))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(output_dir, exist_ok=True)\n",
    "# save  the expressions and llm responses to disk\n",
    "with open(f\"{output_dir}/expressions_base{base}.pkl\", \"wb\") as f:\n",
    "    pickle.dump(expressions, f)\n",
    "with open(f\"{output_dir}/llm_responses_base{base}.pkl\", \"wb\") as f:\n",
    "    pickle.dump(llm_responses, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of wrong answers: tensor(0.)\n",
      "Percentage of correct answers: tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# Get the Accuracy of the LLM responses:\n",
    "wrong_answer_mask = torch.zeros(len(llm_responses), dtype=torch.bool)\n",
    "correct_answer_mask = torch.zeros(len(llm_responses), dtype=torch.bool)\n",
    "real_world_answer_mask = torch.zeros(len(llm_responses), dtype=torch.bool)\n",
    "count = 0\n",
    "for i in range(len(llm_responses)):\n",
    "    try:\n",
    "        correct_response = get_label(expressions[i], base)\n",
    "        real_world_response = None\n",
    "        if base < 10:\n",
    "            real_world_response = get_label(expressions[i], 10)\n",
    "        \n",
    "        llm_response = llm_responses[i].split(\"=\")[1].strip()\n",
    "        llm_response = llm_response.split(\"\\n\")[0].strip()\n",
    "        pred = parse_output(llm_response).upper()\n",
    "\n",
    "\n",
    "        if pred == correct_response:\n",
    "            correct_answer_mask[i] = True\n",
    "        elif real_world_response is not None and pred == real_world_response:\n",
    "            real_world_answer_mask[i] = True\n",
    "        else:\n",
    "            wrong_answer_mask[i] = True\n",
    "    except Exception as e:\n",
    "        print(llm_responses[i])\n",
    "\n",
    "\n",
    "print(\"Percentage of wrong answers:\", wrong_answer_mask.sum()/len(llm_responses))\n",
    "print(\"Percentage of correct answers:\", correct_answer_mask.sum()/len(llm_responses))\n",
    "if base < 10:\n",
    "    print(\"Percentage of real world answers:\", real_world_answer_mask.sum()/len(llm_responses))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_activation_dict={i: torch.zeros(len(activations), 4096) for i in range(32)}\n",
    "for i in range(len(activations)):\n",
    "    for j in range(32):\n",
    "        layer_activation_dict[j][i] = torch.tensor(activations[i][j])\n",
    "\n",
    "with open(f\"{output_dir}/layer_activations_base{base}.pkl\", \"wb\") as f:\n",
    "    pickle.dump(layer_activation_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the probabilities over the next token given the activations.\n",
    "def logit_lens(unembed_weights, final_layer_norm, activations):\n",
    "    \"\"\"\n",
    "    Get the probabilities of the next token given the activations.\n",
    "    \"\"\"\n",
    "\n",
    "    normed_h = final_layer_norm(activations)\n",
    "    logits = torch.matmul(normed_h, unembed_weights.T)\n",
    "    \n",
    "    probs = torch.softmax(logits, dim=-1)\n",
    "    \n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing layer 0...\n",
      "Processing layer 1...\n",
      "Processing layer 2...\n",
      "Processing layer 3...\n",
      "Processing layer 4...\n",
      "Processing layer 5...\n",
      "Processing layer 6...\n",
      "Processing layer 7...\n",
      "Processing layer 8...\n",
      "Processing layer 9...\n",
      "Processing layer 10...\n",
      "Processing layer 11...\n",
      "Processing layer 12...\n",
      "Processing layer 13...\n",
      "Processing layer 14...\n",
      "Processing layer 15...\n",
      "Processing layer 16...\n",
      "Processing layer 17...\n",
      "Processing layer 18...\n",
      "Processing layer 19...\n",
      "Processing layer 20...\n",
      "Processing layer 21...\n",
      "Processing layer 22...\n",
      "Processing layer 23...\n",
      "Processing layer 24...\n",
      "Processing layer 25...\n",
      "Processing layer 26...\n",
      "Processing layer 27...\n",
      "Processing layer 28...\n",
      "Processing layer 29...\n",
      "Processing layer 30...\n",
      "Processing layer 31...\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Process the activations for each layer and all instances and save -- takes around 6-7 minutes\n",
    "layer_probs = {_ : torch.zeros(1000, 1000) for _ in range(32)}\n",
    "correct_token_ids = []\n",
    "\n",
    "layer_activation_dict = pickle.load(open(f\"{output_dir}/layer_activations_base{base}.pkl\", \"rb\"))\n",
    "\n",
    "# Load the unembedding weights and final layer normalization for logit lens\n",
    "unembed_weights = torch.load(f\"{model_name.split('/')[-1]}/unembed_weights.pt\", weights_only=True)\n",
    "final_layer_norm = torch.load(f\"{model_name.split('/')[-1]}/final_layer_norm.pt\", weights_only=False)\n",
    "\n",
    "\n",
    "for layer in range(32):\n",
    "    print(f\"Processing layer {layer}...\")\n",
    "    layer_activations = layer_activation_dict[layer]\n",
    "    with torch.no_grad():\n",
    "        probs = logit_lens(unembed_weights, final_layer_norm, layer_activations)\n",
    "    layer_probs[layer] = probs.cpu()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{output_dir}/logit_lens_results_base{base}.pkl\", \"wb\") as f:\n",
    "    pickle.dump(layer_probs, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (thesis)",
   "language": "python",
   "name": "reasoning-reciting-probing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
